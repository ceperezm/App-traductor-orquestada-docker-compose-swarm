# App de Traducci√≥n Orquestada con Docker Compose y Swarm

üìú **Descripci√≥n general**

Construcci√≥n de una aplicaci√≥n de traducci√≥n de texto que usa un modelo generativo (Gen-AI), registra cada interacci√≥n con MLflow Tracking, y se define y ejecuta usando Docker Compose para el desarrollo local. Posteriormente, se despliega como un stack orquestado en Docker Swarm para demostrar escalabilidad y gesti√≥n de servicios.

üéØ **Requisitos obligatorios**

- ‚úÖ Interfaz web con Gradio (ingreso de texto, selecci√≥n de idioma, resultado)
- ‚úÖ Registro de cada interacci√≥n en MLflow (texto original, idioma, traducci√≥n, timestamp)
- ‚úÖ Entorno de desarrollo local con docker-compose.yml
- ‚úÖ Despliegue en Docker Swarm con docker-stack.yml
- ‚úÖ Imagen publicada en Docker Hub

üèõÔ∏è **Estructura del trabajo**

### Parte A ‚Äî App de traducci√≥n (Desarrollo local)
- Interfaz Gradio con campo texto, selector idioma, bot√≥n traducir, √°rea de resultado
- Integraci√≥n con SDK de Gen-AI para obtener traducciones
- Configuraci√≥n de URI de MLflow desde variable de entorno
- Pruebas locales sin Docker

### Parte B ‚Äî Integraci√≥n con MLflow Tracking
- Creaci√≥n autom√°tica de runs en MLflow por cada traducci√≥n
- Registro de par√°metros (idioma, modelo), m√©tricas (latencia, longitud) y artefactos
- Configuraci√≥n de conexi√≥n remota a servidor MLflow

### Parte C ‚Äî Orquestaci√≥n local con Docker Compose
- Dockerfile para la aplicaci√≥n con Python 3.11
- docker-compose.yml con dos servicios: app-traductor y mlflow-server
- Vol√∫menes persistentes para base de datos y artefactos
- Red com√∫n para comunicaci√≥n entre servicios

### Parte D ‚Äî Despliegue en Producci√≥n con Docker Swarm
- docker-stack.yml adaptado para Swarm con imagen de Docker Hub
- Configuraci√≥n de r√©plicas y pol√≠ticas de reinicio
- Red overlay para comunicaci√≥n multi-nodo
- Escalabilidad din√°mica del servicio

üìÅ **Estructura del proyecto**

```
directorio/
‚îú‚îÄ‚îÄ chatbotgradio.py          # Aplicaci√≥n principal con Gradio
‚îú‚îÄ‚îÄ Dockerfile               # Imagen Docker para la app
‚îú‚îÄ‚îÄ docker-compose.yml       # Orquestaci√≥n local
‚îú‚îÄ‚îÄ docker-stack.yml         # Orquestaci√≥n Swarm
‚îú‚îÄ‚îÄ requirements.txt         # Dependencias Python
‚îî‚îÄ‚îÄ .env                    # Variables de entorno (API_KEY)
```

ÔøΩ **Instalaci√≥n y ejecuci√≥n**

### Desarrollo local
```bash
# 1. Configurar variables de entorno
export OPEN_ROUTER_API_KEY=tu_api_key

# 2. Levantar stack local
docker-compose up --build

# 3. Acceder a las aplicaciones
# Gradio: http://localhost:7860
# MLflow: http://localhost:5000
```

### Producci√≥n con Swarm
```bash
# 1. Inicializar Swarm
docker swarm init

# 2. Publicar imagen en Docker Hub
docker tag app-traductor usuario/traductor-genai:1.0.0
docker push usuario/traductor-genai:1.0.0

# 3. Desplegar stack
docker stack deploy -c docker-stack.yml traductor_stack

# 4. Escalar servicio
docker service scale traductor_stack_app-traductor=3
```

üîß **Componentes t√©cnicos**

### Servicios Docker
- **app-traductor**: Aplicaci√≥n Gradio con l√≥gica de traducci√≥n integrada (puerto 7860)
- **mlflow-server**: Servidor MLflow para tracking de experimentos (puerto 5000)

### Arquitectura General
El proyecto utiliza una arquitectura basada en microservicios ejecutados en contenedores Docker. Los servicios principales son:
- **app-traductor**: Aplicaci√≥n Gradio que incluye la interfaz web y la l√≥gica de traducci√≥n (expuesto en puerto 7860)
- **mlflow-server**: Servidor MLflow para registro y monitoreo de experimentos (expuesto en puerto 5000)

En Docker Compose, los servicios comparten una red bridge y usan vol√∫menes locales. En Swarm, los servicios se ejecutan como r√©plicas dentro de una red overlay distribuida.

### Diferencias entre docker-compose.yml y docker-stack.yml
- **Compose**: Permite build directo desde Dockerfile, orientado a desarrollo local
- **Swarm**: Requiere imagen ya publicada (directiva `image` en lugar de `build`)
- **Deploy**: Swarm utiliza secci√≥n `deploy` para configurar r√©plicas, reinicios y restricciones
- **Redes**: Compose usa `bridge`, Swarm usa `overlay` para comunicaci√≥n multi-nodo
- **Vol√∫menes**: En Swarm deben manejarse mediante drivers distribuidos o declaraci√≥n externa

### Comandos Principales
```bash
# Desarrollo local
docker-compose up -d                    # Levanta servicios locales
docker-compose build                   # Construye im√°genes de desarrollo

# Producci√≥n Swarm
docker swarm init                      # Inicializa cluster Swarm
docker stack deploy -c docker-stack.yml traductor_stack  # Despliega aplicaci√≥n
docker service ls                       # Lista servicios en ejecuci√≥n
docker service scale traductor_stack_app-traductor=3   # Escala r√©plicas
docker push usuario/traductor-genai:1.0.0   # Publica imagen en Docker Hub
docker pull usuario/traductor-genai:1.0.0   # Descarga imagen desde Docker Hub
```

### Observaciones sobre Rendimiento
La latencia del servicio depende de la carga del cluster y del modelo de traducci√≥n utilizado:
- **Entorno local (Compose)**: Latencia baja sin red distribuida
- **Entorno Swarm**: Latencia ligeramente mayor debido al enrutamiento interno entre nodos
- **Calidad de traducci√≥n**: Resultados consistentes para textos cortos y medianos
- **Escalabilidad**: Desempe√±o estable al escalar r√©plicas del servicio

### Modelos de IA disponibles
- Google: gemma-3-27b-it, gemini-2.0-flash-exp
- Qwen: qwen3-14b, qwen-2.5-72b-instruct
- DeepSeek: deepseek-r1-distill-llama-70b, deepseek-r1-0528-qwen3-8b

### Idiomas soportados
Espa√±ol, Ingl√©s, Franc√©s, Alem√°n, Italiano, Portugu√©s, Chino, Japon√©s

üìä **Monitoreo con MLflow**

Cada traducci√≥n registra:
- **Par√°metros**: idioma_origen, idioma_destino, modelo, proveedor, input_length
- **M√©tricas**: latencia_ms, output_length, length_ratio
- **Artefactos**: JSON con timestamp, textos, y m√©tricas completas

üê≥ **Configuraci√≥n Docker**

### Dockerfile
```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY chatbotgradio.py .
EXPOSE 7860
CMD ["sh", "-c", "sleep 10 && python chatbotgradio.py"]
```

### Vol√∫menes persistentes
- `mlflow-db-data`: Base de datos de experimentos
- `mlflow-artifacts-data`: Artefactos y logs

üîç **Verificaci√≥n del despliegue**

```bash
# Ver servicios del stack
docker stack services traductor_stack

# Ver r√©plicas activas
docker service ls

# Ver logs de servicios
docker service logs traductor_stack_app-traductor
```

ÔøΩ **Notas importantes**

- La aplicaci√≥n espera 10 segundos antes de iniciar para asegurar que MLflow est√© disponible
- Los modelos gratuitos de OpenRouter tienen l√≠mites de uso
- Los vol√∫menes aseguran persistencia de datos entre reinicios
- Swarm utiliza routing mesh para balanceo de carga autom√°tico